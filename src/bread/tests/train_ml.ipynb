{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an XGBoost for tracing lineage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bread\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path_to_data = os.path.abspath('data')\n",
    "path_to_colonies = os.path.abspath('data/colonies')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_209674/2389213116.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load the 5 colony ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcolonies_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     temp_colony = pd.read_csv(os.path.join(\n\u001b[0;32m----> 7\u001b[0;31m         path_to_colonies, 'colony00{}_lineage.csv'.format(i)))\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtemp_colony\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'colony'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcolonies_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolonies_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_colony\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcolonies_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolonies_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lineage_tracing/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# load the 5 colony ground truth\n",
    "colonies_gt = pd.DataFrame()\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    temp_colony = pd.read_csv(os.path.join(\n",
    "        path_to_colonies, 'colony00{}_lineage.csv'.format(i)))\n",
    "    temp_colony['colony'] = i\n",
    "    colonies_gt = colonies_gt.append(temp_colony)\n",
    "colonies_gt = colonies_gt.reset_index(drop=True)\n",
    "colonies_gt.rename(columns={'# parent_id': 'parent_GT'}, inplace=True)\n",
    "colonies_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bread.algo.lineage import LineageGuesserML\n",
    "from bread.data import Segmentation, Lineage, SegmentationFile\n",
    "\n",
    "\n",
    "def extract_features(segmentation_path, args):\n",
    "    candidate_features = pd.DataFrame(columns=['bud_id', 'candid_id', 'time_id', 'feature1', 'feature2',\n",
    "                                      'feature3', 'feature4', 'feature5', 'feature6', 'feature7', 'feature8', 'feature9', 'feature10'])\n",
    "    segmentation = SegmentationFile.from_h5(\n",
    "        segmentation_path).get_segmentation('FOV0')\n",
    "    guesser = LineageGuesserML(\n",
    "        segmentation=segmentation,\n",
    "        nn_threshold=args[\"nn_threshold\"],\n",
    "        flexible_nn_threshold=args[\"flexible_nn_threshold\"],\n",
    "        num_frames_refractory=args[\"num_frames_refractory\"],\n",
    "        num_frames=args[\"num_frames\"],\n",
    "        bud_distance_max=args[\"bud_distance_max\"]\n",
    "    )\n",
    "    bud_ids, time_ids = segmentation.find_buds(\n",
    "    ).bud_ids, segmentation.find_buds().time_ids\n",
    "    for i, (bud_id, time_id) in enumerate(zip(bud_ids, time_ids)):\n",
    "        frame_range = guesser.segmentation.request_frame_range(\n",
    "            time_id, time_id + guesser.num_frames)\n",
    "        num_frames_available = guesser.num_frames\n",
    "        if len(frame_range) < 2:\n",
    "            # raise NotEnoughFramesException(bud_id, time_id, guesser.num_frames, len(frame_range))\n",
    "            print(\"Not enough frames for bud {} at time {}. Only {} frames available.\".format(\n",
    "                bud_id, time_id, len(frame_range)))\n",
    "        if len(frame_range) < guesser.num_frames:\n",
    "            num_frames_available = len(frame_range)\n",
    "            # warnings.warn(NotEnoughFramesWarning(bud_id, time_id, guesser.num_frames, len(frame_range)))\n",
    "            print(\"Not enough frames for bud {} at time {}. Only {} frames available.\".format(\n",
    "                bud_id, time_id, len(frame_range)))\n",
    "        # check the bud still exists !\n",
    "        for time_id_ in frame_range:\n",
    "            if bud_id not in guesser.segmentation.cell_ids(time_id_):\n",
    "                # raise LineageGuesserExpansionSpeed.BudVanishedException(bud_id, time_id_)\n",
    "                print(\"Bud {} vanished at time {}\".format(bud_id, time_id_))\n",
    "        selected_times = [i for i in range(\n",
    "            time_id, time_id + num_frames_available)]\n",
    "        candidate_parents = guesser._candidate_parents(\n",
    "            time_id, nearest_neighbours_of=bud_id)\n",
    "        summary_features = np.zeros(\n",
    "            (len(candidate_parents), guesser.number_of_features), dtype=np.float64)\n",
    "        for c_id, candidate in enumerate(candidate_parents):\n",
    "            try:\n",
    "                features, _ = guesser._get_ml_features(\n",
    "                    bud_id, candidate, time_id, selected_times)\n",
    "                new_row = {'bud_id': bud_id, 'candid_id': candidate, 'time_id': time_id, 'feature1': features[0], 'feature2': features[1], 'feature3': features[2], 'feature4': features[\n",
    "                    3], 'feature5': features[4], 'feature6': features[5], 'feature7': features[6], 'feature8': features[7], 'feature9': features[8], 'feature10': features[9]}\n",
    "                candidate_features = candidate_features.append(\n",
    "                    new_row, ignore_index=True)\n",
    "            except:\n",
    "                print(\"Error for bud {} at time {} with candidate {}\".format(\n",
    "                    bud_id, time_id, candidate))\n",
    "    return candidate_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features for each colony and save them to a csv file. This takes a while. But after this, we only need to load the csv files. every time.\n",
    "colony_candidate_features = [0, 0, 0, 0, 0, 0]\n",
    "args = {\"nn_threshold\": 8.0, \"flexible_nn_threshold\": True,\n",
    "        \"num_frames_refractory\": 0, \"num_frames\": 4, \"bud_distance_max\": 10}\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    print(\"finding features for colony {}\".format(i))\n",
    "    colony_candidate_features[i] = extract_features(os.path.join(\n",
    "        path_to_colonies, 'colony00{}_segmentation.h5'.format(i)), args)\n",
    "    colony_candidate_features[i]['colony'] = i\n",
    "    # remove rows with time_id = 0\n",
    "    colony_candidate_features[i] = colony_candidate_features[i][colony_candidate_features[i].time_id != 0]\n",
    "    # remove rows with bud_id == candid_id (this shouldn't happen in theory)\n",
    "    colony_candidate_features[i] = colony_candidate_features[i][colony_candidate_features[i].bud_id !=\n",
    "                                                                colony_candidate_features[i].candid_id]\n",
    "    # save to csv\n",
    "    colony_candidate_features[i].to_csv(os.path.join(\n",
    "        path_to_colonies, 'colony00{}_candidate_features.csv'.format(i)), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonies_features = pd.DataFrame()\n",
    "\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    temp_colony = pd.read_csv(os.path.join(\n",
    "        path_to_colonies, 'colony00{}_candidate_features.csv'.format(i)))\n",
    "    colonies_features = colonies_features.append(temp_colony)\n",
    "colonies_features = colonies_features.reset_index(drop=True)\n",
    "colonies_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for training XGBoost\n",
    "import numpy as np\n",
    "import itertools\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_features(features_all, lineage_gt):\n",
    "    # Generate np array of feature sets for each bud\n",
    "    df1 = lineage_gt.copy()\n",
    "    # remove the rows with parent_GT = -1 (no parent) and the rows with candid_GT = -2 (disappearing buds)\n",
    "    df1 = df1.loc[df1.parent_GT != -1]\n",
    "    df1 = df1.loc[df1.parent_GT != -2]\n",
    "    df2 = features_all.copy()\n",
    "\n",
    "    features_list = []\n",
    "    parent_index_list = []\n",
    "    candidate_list = []\n",
    "    for bud, colony in df1[['bud_id', 'colony']].values:\n",
    "        bud_data = df2.loc[(df2['bud_id'] == bud) & (df2['colony'] == colony)]\n",
    "        candidates = bud_data['candid_id'].to_numpy()\n",
    "        if candidates.shape[0] < 4:\n",
    "            candidates = np.pad(\n",
    "                candidates, ((0, 4 - candidates.shape[0])), mode='constant', constant_values=-3)\n",
    "        features = bud_data[['feature1', 'feature2', 'feature3', 'feature4', 'feature5',\n",
    "                             'feature6', 'feature7', 'feature8', 'feature9', 'feature10']].to_numpy()\n",
    "        if features.shape[0] < 4:\n",
    "            features = np.pad(features, ((\n",
    "                0, 4 - features.shape[0]), (0, 0)), mode='constant', constant_values=-1)\n",
    "        if features.shape[0] > 4:\n",
    "            sorted_indices = np.argsort(features[:, 0])\n",
    "            print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(df1.loc[(df1['bud_id'] == bud) & (\n",
    "                df1['colony'] == colony), 'parent_GT']))\n",
    "            # slice the top 4 rows\n",
    "            k = 4\n",
    "            features = features[sorted_indices[:k]]\n",
    "            candidates = candidates[sorted_indices[:k]]\n",
    "\n",
    "        parent = int(df1.loc[(df1['bud_id'] == bud) & (\n",
    "            df1['colony'] == colony), 'parent_GT'])\n",
    "        # print(bud, colony, parent)\n",
    "        # print(candidates)\n",
    "        if(parent not in candidates):\n",
    "            print('parent not in candidates', bud, colony, candidates, parent)\n",
    "            # remove this from the df\n",
    "            df1.drop(df1.loc[(df1['bud_id'] == bud) & (df1.colony == colony)].index,\n",
    "                     inplace=True)\n",
    "            continue\n",
    "        else:\n",
    "            parent_index = np.where(candidates == parent)[0][0]\n",
    "\n",
    "        parent_index_list.append(parent_index)\n",
    "        features_list.append(features)\n",
    "        candidate_list.append(candidates)\n",
    "    df1['features'] = features_list\n",
    "    df1['candidates'] = candidate_list\n",
    "    df1['parent_index_in_candidates'] = parent_index_list\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonies_matrix_features = get_matrix_features(colonies_features, colonies_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_feature_importance(bst, figsize=(10, 5), title=''):\n",
    "    \"\"\"\n",
    "    Plots the feature importances of an XGBoost model\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    feature_importance = bst.get_score(importance_type='weight')\n",
    "    feature_importance = {k: v for k, v in sorted(\n",
    "        feature_importance.items(), key=lambda item: item[1], reverse=True)}\n",
    "    plt.bar(range(len(feature_importance)), list(\n",
    "        feature_importance.values()), align='center')\n",
    "    plt.xticks(range(len(feature_importance)), list(\n",
    "        feature_importance.keys()), rotation=90)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Feature importance score')\n",
    "    plt.title('Feature importance for ' + title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_eval_metrics(evals_result, title=''):\n",
    "    \"\"\"\n",
    "    Plot evaluation metrics from an XGBoost model\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    try:\n",
    "        plt.plot(evals_result['train']['merror'], label='Train')\n",
    "        plt.plot(evals_result['test']['merror'], label='Validation')\n",
    "\n",
    "    except:  # For binary classification, the loss is 'error'\n",
    "        plt.plot(evals_result['train']['error'], label='Train')\n",
    "        plt.plot(evals_result['test']['error'], label='Validation')\n",
    "\n",
    "    plt.xlabel('Number of Boosting Rounds')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Error vs Number of Boosting Rounds for ' + title)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    plt.figure()\n",
    "    plt.imshow(confusion_matrix(y_true, y_pred), cmap='Blues')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_matrix(s):\n",
    "    # Do heading\n",
    "    print(\"     \", end=\"\")\n",
    "    for j in range(len(s[0])):\n",
    "        print(\"%5d \" % j, end=\"\")\n",
    "    print()\n",
    "    print(\"     \", end=\"\")\n",
    "    for j in range(len(s[0])):\n",
    "        print(\"------\", end=\"\")\n",
    "    print()\n",
    "    # Matrix contents\n",
    "    for i in range(len(s)):\n",
    "        print(\"%3d |\" % (i), end=\"\")  # Row nums\n",
    "        for j in range(len(s[0])):\n",
    "            print(\"%.3f \" % (s[i][j]), end=\"\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_xgboost_matrix(matrix_features_df, augment=True):\n",
    "    X = matrix_features_df['features'].to_numpy()\n",
    "    y = matrix_features_df['parent_index_in_candidates'].to_numpy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=True)\n",
    "    if augment:\n",
    "        X_train, y_train = generate_all_permutations(X_train, y_train)\n",
    "    X_train = flatten_3d_array(X_train)\n",
    "    X_test = flatten_3d_array(X_test)\n",
    "\n",
    "    # Train the default XGBoost model\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    params = {'objective': 'multi:softmax',\n",
    "              'num_class': 4, 'eval_metric': 'merror'}\n",
    "    model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "    # Make predictions and evaluate the model\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    preds = model.predict(dtest)\n",
    "    preds = np.round(preds)\n",
    "    print(\"Accuracy of the default model:\", \"%.4f \" %\n",
    "          accuracy_score(y_test, preds))\n",
    "\n",
    "    # Searching for optimal tree depth to prevent overfitting\n",
    "    # early stopping rounds specidies the number of epochs after which the training will stop if there is no improvement in accuracy\n",
    "    best_params = grid_train_xgboost(\n",
    "        X_train, y_train, X_test, y_test, early_stopping_rounds=10, num_boost_round=100)\n",
    "\n",
    "    print('best_params', best_params)\n",
    "\n",
    "    # Make predictions with best_params\n",
    "    print('=======================  best model  ========================')\n",
    "    evals_result = {}\n",
    "    bst = xgb.train(best_params, dtrain, num_boost_round=200, early_stopping_rounds=20, evals=[\n",
    "        (dtest, 'test'), (dtrain, 'train')], verbose_eval=False, evals_result=evals_result)\n",
    "    # Make predictions and evaluate the best model\n",
    "    preds = bst.predict(dtest)\n",
    "    preds = np.round(preds)\n",
    "    print(\"Accuracy of the best model:\", \"%.4f \" %\n",
    "          accuracy_score(y_test, preds))\n",
    "    plot_eval_metrics(evals_result, title='best model')\n",
    "\n",
    "    # train model with custom parameters\n",
    "    print('=======================  custom model  ========================')\n",
    "    custom_params = {'objective': 'multi:softmax', 'num_class': 4,\n",
    "                     'max_depth': 10, 'min_child_weight': 5, 'eval_metric': 'merror'}\n",
    "    evals_result = {}\n",
    "    model = xgb.train(custom_params, dtrain, num_boost_round=200, early_stopping_rounds=20, evals=[\n",
    "        (dtest, 'test'), (dtrain, 'train')], verbose_eval=False, evals_result=evals_result)\n",
    "    # Make predictions and evaluate the custom model\n",
    "    preds = model.predict(dtest)\n",
    "    preds = np.round(preds)\n",
    "    print(\"Accuracy of the custom model:\", \"%.4f \" %\n",
    "          accuracy_score(y_test, preds))\n",
    "    plot_eval_metrics(evals_result, title='custom model')\n",
    "    plot_feature_importance(model, title='custom model')\n",
    "    return model, bst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, bst = train_xgboost_matrix(colonies_matrix_features, augment=True, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model with custom parameters\n",
    "best_model_path = 'best_model.json'\n",
    "custom_model_path = 'custom_model.json'\n",
    "model.save_model(custom_model_path)\n",
    "bst.save_model(best_model_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on unseen images\n",
    "\n",
    "we test on a colony that haven't been seen by the train set at all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colony0_segmentation_path = '/home/farzaneh/Documents/Bread/bread/src/bread/tests/data/V2022_09_19_HTB2_mCh_MYO1-GFP_50_ms/FOV0_segmentation_T0_to_T146_trimmed.h5'\n",
    "colony0_lineage_GT_path = '/home/farzaneh/Documents/Bread/bread/src/bread/tests/data/V2022_09_19_HTB2_mCh_MYO1-GFP_50_ms/FOV0_lineage_T0_to_T146.csv'\n",
    "\n",
    "colony0_lineage_gt = pd.read_csv(colony0_lineage_GT_path)\n",
    "colony0_lineage_gt.rename(columns={'parent_id': 'parent_GT'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = {\"nn_threshold\": 8.0, \"flexible_nn_threshold\": True,\n",
    "        \"num_frames_refractory\": 0, \"num_frames\": 4, \"bud_distance_max\": 10.0}\n",
    "colony0_features = extract_features(colony0_segmentation_path, args)\n",
    "colony0_features['colony'] = [0 for i in range(len(colony0_features))]\n",
    "colony0_lineage_gt = pd.read_csv(colony0_lineage_GT_path).rename(\n",
    "    columns={'parent_id': 'parent_GT'})\n",
    "colony0_lineage_gt['colony'] = [0 for i in range(len(colony0_lineage_gt))]\n",
    "colony0_matrix_features = get_matrix_features(\n",
    "    colony0_features, colony0_lineage_gt)\n",
    "X = colony0_matrix_features['features'].to_numpy()\n",
    "y = colony0_matrix_features['parent_index_in_candidates'].to_numpy()\n",
    "\n",
    "X = flatten_3d_array(X)\n",
    "dtest = xgb.DMatrix(X, label=y)\n",
    "saved_model = xgb.Booster()\n",
    "saved_model.load_model(best_model_path)\n",
    "saved_model_preds = saved_model.predict(dtest)\n",
    "saved_model_preds = np.round(saved_model_preds)\n",
    "print(\"Accuracy of the best saved model:\", \"%.4f \" %\n",
    "      accuracy_score(y, saved_model_preds))\n",
    "print(np.sum(saved_model_preds != y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the accuracy is better when we only use the first 100 cells.\n",
    "trim_data = colony0_matrix_features.loc[colony0_matrix_features['time_index'] < 50]\n",
    "X = trim_data['features'].to_numpy()\n",
    "y = trim_data['parent_index_in_candidates'].to_numpy()\n",
    "\n",
    "X = flatten_3d_array(X)\n",
    "dtest = xgb.DMatrix(X, label=y)\n",
    "saved_model_preds = saved_model.predict(dtest)\n",
    "saved_model_preds = np.round(saved_model_preds)\n",
    "print(\"Accuracy of the saved model for first frames:\", \"%.4f \" %\n",
    "      accuracy_score(y, saved_model_preds))\n",
    "print(np.sum(saved_model_preds != y))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the accuracy for 100 first frames is better than for all frames (146) (between 3 to 6 percents difference). The accuracy for 50 first frame is also around the same and it's close to validation prediction in model. we can conclude that the prediction get harder when image is much more crowded.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add FOV0 buds to colonies and train on all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 10, \"display.max_columns\", 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix_features = colony0_matrix_features.append(\n",
    "    colonies_matrix_features).reset_index(drop=True)\n",
    "all_matrix_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test on the combined data\n",
    "\n",
    "model, bst = train_xgboost_matrix(all_matrix_features, augment=True, )\n",
    "model_path = 'model_all_colonies.json'\n",
    "model.save_model(model_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train on 4 colonies and test on 2\n",
    "\n",
    "colony 4 and 5 have chosen for test because 4 was a problematic colony and 5 was a normal one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_features = all_matrix_features[~ (\n",
    "    (all_matrix_features['colony'] == 4) | (matrix_feature_df['colony'] == 5))]\n",
    "test_matrix_features = all_matrix_features[(\n",
    "    all_matrix_features['colony'] == 4) | (matrix_feature_df['colony'] == 5)]\n",
    "X_train = train_matrix_features['features'].to_numpy()\n",
    "X_test = test_matrix_features['features'].to_numpy()\n",
    "y_train = train_matrix_features['parent_index_in_candidates'].to_numpy()\n",
    "y_test = test_matrix_features['parent_index_in_candidates'].to_numpy()\n",
    "# Train the default XGBoost model\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "params = {'objective': 'multi:softmax',\n",
    "          'num_class': 4, 'eval_metric': 'merror'}\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "# Make predictions and evaluate the model\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "preds = bst.predict(dtest)\n",
    "preds = np.round(preds)\n",
    "print(\"Accuracy of the default model:\", \"%.4f \" %\n",
    "\n",
    "      accuracy_score(y_test, preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpbs_bread",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
